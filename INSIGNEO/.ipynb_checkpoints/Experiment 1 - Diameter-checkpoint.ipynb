{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INSIGNEO CORONARY RESISTANCE 2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 1 - ARTERY DIAMETER AND MYOCARDIAL RESISTANCE CORRELATION ANALYSIS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The aim of this experiment is to  analyze if information about the diameter of coronary arteries can be used to estimate the coronary resistance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from pandas import ExcelWriter\n",
    "from pandas import ExcelFile\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from math import isnan\n",
    "from scipy import stats\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Importing scikit-learn ML model for linear regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the data\n",
    "data_path = \"../DATASET/\"\n",
    "data_file_name = \"MR_data_Feb19.xlsx\"\n",
    "data_file = data_path + data_file_name\n",
    "rawdata = pd.read_excel(data_file)\n",
    "rawdata_array = rawdata.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now I will create a list with the diameters that are going to be used for the calculations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               2\n",
      "0     2644637000\n",
      "1     7398694000\n",
      "2     8589303000\n",
      "3    13628250000\n",
      "4     6608665000\n",
      "5     7151671000\n",
      "6    25664450000\n",
      "7     3578790000\n",
      "8    28207240000\n",
      "9     4373292000\n",
      "10    4802398000\n",
      "11    4406385000\n",
      "12    5151203000\n",
      "13    5764038000\n",
      "14     764847900\n",
      "15    8457512000\n",
      "16    7392949000\n",
      "17    8323396000\n",
      "18    4655535000\n",
      "19    5557381000\n",
      "20   21567120000\n",
      "21   11399450000\n",
      "22   25049400000\n",
      "23    6158909000\n",
      "24    6580821000\n",
      "25   27278210000\n",
      "26    4086333000\n",
      "27    3992017000\n",
      "28    2610621000\n",
      "29    4278811000\n",
      "..           ...\n",
      "127  14608570000\n",
      "128  37693260000\n",
      "129  10962340000\n",
      "130   6421114000\n",
      "131   7839131000\n",
      "132   6445721000\n",
      "133   5690933000\n",
      "134   8580199000\n",
      "135   9149940000\n",
      "136  12812060000\n",
      "137   2749412000\n",
      "138   6396323000\n",
      "139   5343108000\n",
      "140   4527280000\n",
      "141   5915748000\n",
      "142   3695038000\n",
      "143   7213642000\n",
      "144   9198177000\n",
      "145   5760464000\n",
      "146   2782166000\n",
      "147  17894910000\n",
      "148  28505340000\n",
      "149   7489025000\n",
      "150   5430436000\n",
      "151  11636180000\n",
      "152   7202002000\n",
      "153   7781409000\n",
      "154   6038216000\n",
      "155  14589700000\n",
      "156   3054534000\n",
      "\n",
      "[157 rows x 1 columns]\n",
      "                 2\n",
      "count          157\n",
      "unique         157\n",
      "top     3578790000\n",
      "freq             1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aldair\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "# Collect labels from dataset\n",
    "diameter_types = rawdata_array[0,5:8]\n",
    "#print(diameter_types)\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "labels = encoder.fit_transform(diameter_types)\n",
    "y = labels # outccome\n",
    "\n",
    "# Create a dataframe from the dataset\n",
    "df = pd.DataFrame(rawdata_array)\n",
    "\n",
    "# Create subset for individual diameter columns\n",
    "x1 = df[[2]]\n",
    "print(x1)\n",
    "\n",
    "# importing regex module \n",
    "import re \n",
    "    \n",
    "# removing null values to avoid errors \n",
    "x1.dropna(inplace = True)  \n",
    "\n",
    "# percentile list \n",
    "perc =[.20, .40, .60, .80] \n",
    "  \n",
    "# list of dtypes to include \n",
    "include =['object', 'float', 'int'] \n",
    "  \n",
    "# calling describe method \n",
    "desc = x1.describe(percentiles = perc, include = include) \n",
    "  \n",
    "# display \n",
    "print(desc) \n",
    "\n",
    "\n",
    "#df = pd.DataFrame(diameter_values)\n",
    "##print(df.describe())\n",
    "\n",
    "\n",
    "#Max_diameters = diameter_values[0:3].max() \n",
    "#print(\"Max values:\\n\",Max_diameters)\n",
    "#Min_diameters = diameter_values[0:3].min()\n",
    "#print(\"\\nMin values for:\\n\",Min_diameters)\n",
    "#Mean_of_diameters = diameter_values[0:3].mean()\n",
    "#print(\"\\n Mean values:\\n\",Mean_of_diameters)\n",
    "#Std_diviation_of_diameters = diameter_values[0:3].std()\n",
    "#print(\"\\n Standard diviation:\\n\",Std_diviation_of_diameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Xpartial = np.delete(diameter_values, np.s_[0])\n",
    "#print(diameter_values)\n",
    "#print(Xpartial)\n",
    "\n",
    "\n",
    "for row in diameter_values:\n",
    "    for element in row:\n",
    "        if (np.isnan(element)): \n",
    "            print(element) \n",
    "            \n",
    "           # Xpartial = np.delete(int(diameter_values), row)\n",
    "            print(row)\n",
    "    \n",
    "\n",
    "#or i in range(len(diameter_values)):\n",
    " #  for j in range(len(Xpartial[0])):\n",
    "  #     rmatrix = diameter_values[i][j] - Xpartial[i][j]\n",
    "#for in rmatrix:\n",
    " #  print(r)\n",
    "    \n",
    "#print(check)\n",
    "\n",
    "flow_type_encoded = encoder.fit_transform(diameter_types)\n",
    "#from sklearn.preprocessing import OneHotEncoder\n",
    "#encoderOH = OneHotEncoder()\n",
    "#cat1 = encoderOH.fit_transofrm(flow_type_encoded.reshape(-1,1)).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
